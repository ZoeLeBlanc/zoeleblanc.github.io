[{"id":"2015-03-10-snow-days-and-twitter-reporting","name":"2015-03-10-snow-days-and-twitter-reporting","content":">This post is one I wrote for VIDL in the middle of the first bizarre snowstorm that gripped Tennessee in February. Until moving to Nashville, I spent 23 years living through harsh Canadian winters (any Canadian who knows I'm from Toronto is rolling their eyes at this point), and so I was use to just slogging through giant snowstorms. Yet this past February and March, Nashville and large parts of Tennessee shut down completely in the face of unprecedented amount of snow and ice (a few inches of each, which is essentially spring in Canada but I digress again). Unsure of what exactly was going on, I turned to twitter for the latest updates. I was amazed with what I found, which was a robust community of citizen journalists sharing weather updates and measurements. So I did what anyone would when snowed in, I decided to try out some network graphing analysis.\n\nThough today is a snow day at Vanderbilt Campus, we at VIDL never let a little bit of weather stop us. In honor of today's storm, this post is a look at how Tennesseans are using Twitter to report on the storm. One of my favorite topics is the role of citizens in the new digital age and so with all the tweets and pics of the bad weather, I wanted to see how these networks are operating.\n\n\nUsing the twitter tag [#tspotter](https://twitter.com/hashtag/tspotter?f=realtime&src=hash), I used Martin Hawksey's [TAGS API](https://tags.hawksey.info/get-tags/) to analyze the network data. TAGS is much easier to use than Gephi or other network analysis tools, and is free, which is rare. All you have to do is copy TAGS as a google doc and authorize your twitter account. After that you run the script, which aggregates all the 3000 latest tweets from the last week. #tspotter had about 1200 unique tweets, and I used Hawksey's TAGSExplorer to visualize the network.\n[Read the rest here...](https://my.vanderbilt.edu/vidl/2015/02/snow-days-twitter-reporting/)\n\n![picofvandyice]({{site.baseurl}}/assets/img/picofvandyice.jpg)\nPicture of Ice on Vanderbilt Campus by @ewillmot\n\nUsing the twitter tag [#tspotter](https://twitter.com/hashtag/tspotter?f=realtime&amp;src=hash), I used Martin Hawksey's [TAGS API](https://tags.hawksey.info/get-tags/) to analyze the network data. TAGS is much easier to use than Gephi or other network analysis tools, and is free, which is rare. All you have to do is copy TAGS as a google doc and authorize your twitter account. After that you run the script, which aggregates all the 3000 latest tweets from the last week. #tspotter had about 1200 unique tweets, and I used Hawksey's TAGSExplorer to visualize the network.\n\n![tspotter1]({{site.baseurl}}/assets/img/tspotter1.jpg)\nNetwork of replies from #tspotter\n\nThis first graph is of the replies from #tspotter, and shows a very loose network with the exception of @NashSeverWX and @NWSNashville. You can inspect the dynamic network [here](http://hawksey.info/tagsexplorer/?key=19uW2gLmN-fFdg1EhCZM_GAplwpdRUDiNLKizwdoCfL8&amp;gid=400689247).\n\n![tspotter2]({{site.baseurl}}/assets/img/tspotter2.jpg)\nNetwork of replies and mentions of #tspotter\n\nThis second graph of replies and mentions of #tspotter is starting to show a more dense network, though still with a lot of outliers. You can explore the dynamic network [here](http://hawksey.info/tagsexplorer/?key=19uW2gLmN-fFdg1EhCZM_GAplwpdRUDiNLKizwdoCfL8&amp;gid=400689247&amp;mentions=true).\n\n![tspotter3]({{site.baseurl}}/assets/img/tspotter3.jpg)\nNetwork of replies, mentions, and retweets of #tspotter\n\nThis final graph of the replies, mentions, and retweets of #tspotter is as you would expect much more dense. However, I was really blown away with how much this graph seems to represent a community of Tennesseans taking to twitter to show their experiences of this rare metereological event. The fact that the top tweeter is [@NashSevereWX](https://twitter.com/NashSevereWx), which relies on social media to report on weather, I think speaks to the growth of social media as a tool for citizen participation. You can check out the final graph [here](http://hawksey.info/tagsexplorer/?key=19uW2gLmN-fFdg1EhCZM_GAplwpdRUDiNLKizwdoCfL8&amp;gid=400689247&amp;mentions=true&amp;retweets=true) and feel free to post your pics below or tweet us [@VUdigital](http://twitter.com/VUdigital).\n\nStay warm Tennessee!\n\n"},{"id":"2015-03-18-citizen-journalism-and-infographics","name":"2015-03-18-citizen-journalism-and-infographics","content":"> This post was one I produced for my VIDL Series \"In Pursuit of Digital Pedagogy\", which you can read [here.](https://my.vanderbilt.edu/vidl/2015/04/in-pursuit-of-digital-pedagogy-1/)\n\n### In Pursuit of Digital Pedagogy: A Series on Digital Tools in the Classroom\n\nFor this post, I decided to *investigate* a digitally based methodology that I have often stumbled upon but yet to try - *Citizen Journalism*. If you are unfamiliar with the term, I would suggest that you do a quick web search just to see the wealth of examples and debates about Citizen Journalism.\n\nWhat attracted me to this method was the ethos of Citizen Journalism, which emphasizes the use of digital and open source tools to collaborate and be engaged as citizens. To explore this method, I decided to adopt a meta-approach of trying out a potential digital tool that I wanted to use in my classroom as a medium for my post. I explain the methodology of Citizen Journalism in my first infographic so click [here](https://magic.piktochart.com/output/2690247-the-rise-of-citizen-journalism-c) to see how this method could work for you.\n\n**So what is an infographic?**\n\nDon't worry if you've never heard of an infographic, the concept is pretty straight forward. To quote Wikipedia, [\"Information graphics or infographics are graphic visual representations of information, data or knowledge intended to present complex information quickly and clearly\"](https://en.wikipedia.org/wiki/Infographic). In my opinion, infographics or infograms are a great method for creating an eye catching visualization of an argument that forces both the 'producer' and 'consumer' to actively consider how information is presented and organized. This method is particularly suited to visualizing data or analyzing visual media.\n\n**So why infographics? And how can infographics work in the classroom?**\n\nHave you ever had a student challenge your revisions or comments on a paper, calling the changes simply *stylistic* ones?\n\nThen an infographic is for you!\n\nIn all seriousness though, this method is great for challenging students conceptions about the importance of style when presenting an argument both in the written and visual form. Often academics scoff at concerns of aesthetics or design, and students tend to treat these issues as somehow less serious ones. Yet, how we present our information is directly tied to our ability to communicate effectively. Furthermore, infographics seem deceptively easy at first glance, but require a whole set of digital and critical skills, which really embodies the goals of digital learning.\n\n**Using Infographics in the Classroom**\n\n*Instead of assigning a writing assignment, why not try an infographic?*\n\nMost humanities classes usually assign a smaller, low stakes writing assignment in the first few weeks of a course to get students thinking about larger paper topics and exposed to academic writing conventions. While, I'm still a proponent of writing assignments, I believe using an infographic can further the overall goal of these assignments.\n\nSo instead of a first writing assignment have your students build an infographic about whatever issue or problem relates to your course. Be sure to walk through with students on how to use an infographic and the principles of good design. If you google for design tips for infographics you'll find lots of hits, and I personally found the [subreddit Infographics](https://www.reddit.com/r/Infographics/) helpful.\n\nNext step, have your students post their infographic to the course website or virtual collaborative space, and either in class or digitally have your students comment and offer suggestions on the infographics. Revising an infographic seems more low-stakes than revising an entire essay, but the results can be just as worthwhile.\n\nWith the revised infographics, now have the students translate the infographic to a written version in either a blog post or an essay.\n\nSeems easy? Let me assure you, after creating my own infographics this assignment will be both a challenge and eye-opening for your students. In limiting the amount of text, students will be forced to distill their arguments and make sure that their evidence actually furthers their thesis. Furthermore, deciding what to visualize and how is an additional challenge and really forces the creator to think about the shape of an argument.\n\n**So what tools should you use and how difficult are infographics to learn?**\n\nBefore starting this project, I had always wanted to try out making my own infographic but had zero previous experience. [Full disclosure, I wish I had spent more time on thinking and reading about design prior to making my infographics.] If like me you're a neophyte when it comes to design, this assignment may be a great opportunity to either bring in an outside expert from campus or the public to talk about design prior to staring the assignment.\n\nIn terms of tools, I tried out two free tools: [Infogr.am](https://infogr.am/) and [Piktochart](https://magic.piktochart.com/). Both tools are user friendly and allow for a diverse range of multimedia in the infographic. For this project, I decided to use Piktochart because of the wider ability to embed media. However, if I wanted to visualize any graphs I probably would have chosen Infogram.\n\nPiktochart was really easy to use and allowed me to move around images, pictures, and embed videos from Youtube and Vimeo. I particularly enjoyed the easy of uploading images and the fairly wide range of graphics already available on the site. I started my infographics from scratch but there are numerous templates to choose from for free. Finally, Piktochart allows continuous web publishing, has a slideshow capability, and looks really clean and powerful when finished. One difficulty was embedding piktochart onto my Wordpress blog, which initially didn't work great. Luckily, there is a free [github Wordpress shortcode](https://github.com/birgire/wp-piktochart-embed) for Piktochart that you can easily upload into your plugins and works seemlessly with Piktochart.\n\n**Overall Assessment of Piktochart**\n\n    Allows for Creative Content Creation: A\n    Ease of Use: A\n    Open Source: A+\n    Ease to Publish or Share: B (because of issues in embedding Piktochart on wordpress, though its not impossible)\n    Ease of Assessing Learning: A\n    Ability to Integrate into Curriculum: A\n\n**Recommendation: Great tool with a low barrier to use and high potential for innovative learning.**\n\n**Final Thoughts**\n\nIn the end, what I actually created was not really what I set out to originally, and I'm not sure the final product is really in line with a traditional infographic. Instead, I feel like I unintentionally built more of a multi-media essay about Citizen Journalism. This unintentional final product really embodies for me both the concerns and benefits of digital tools - the possibility of creating unexpected results. I'll go into more about multi-media or transmedia essays in my next post, but take a look at how I organized and presented information. You can judge whether the end result was a success, but overall the experience was certainly informative on a number of levels.\n\n**Want more information?**\n\nCheck out The Vanderbilt CFT's great guide on Visualization and Teaching, which has a section on infographics that you can look at [here](http://cft.vanderbilt.edu/guides-sub-pages/visual-thinking/#dataviz). On HASTAC, Lorna Gonzalez has a [post](http://www.hastac.org/blogs/lorna-gonzalez/2014/02/13/infovisual-literacy-teaching-ela-high-school) about using infographics in the High School classroom, and provides a lot of detailed analysis on initial setup, working through the assignment, and assessment.\n\nHave you tried using infographics in your classroom? If you haven't what are the concerns that keep you from trying? If you have, any tips or suggestions? I would love to hear about your experiences so please comment or [tweet me](http://twitter.com/home/?status=@Zoe_LeBlanc)\n\nNow to visualize ALL the things.\n\nZoe\n \n"},{"id":"2015-04-20-citizen-journalism-and-video-essays","name":"2015-04-20-citizen-journalism-and-video-essays","content":"> This post was one I produced for my VIDL Series \"In Pursuit of Digital Pedagogy\", which you can read [here.](https://my.vanderbilt.edu/vidl/2015/04/in-pursuit-of-digital-pedagogy-3/)\n\n### In Pursuit of Digital Pedagogy: A Series on Digital Tools in the Classroom\n\nNew to the series? Check out [Part I](https://my.vanderbilt.edu/vidl/2015/03/in-pursuit-of-digital-pedagogy-citizen-journalism-infographics/) and [Part II](https://my.vanderbilt.edu/vidl/2015/04/in-pursuit-of-digital-pedagogy-citizen-journalism-multimedia-essays/)\n\nSo we're finally at the end of this series on Citizen Journalism, and as is often the case the end point is much different than the one I envisioned in September when I first proposed the idea to the VIDL team. Since my first forays into this method, I've learned a number of new digital tools, explored alternatives to Citizen Journalism, and finally, created what I hope is a productive and effective alternative method for teaching - Citizen Research.\n\nFor this final post, I continued my infographic/multimedia essay piece, but I also blogged on this method of Citizen research, so read the post . You can find the final post [here at Medium](https://medium.com/@zoe_leblanc/in-pursuit-of-digital-pedagogy-a-vidl-blog-post-citizen-researcher-digitally-born-pedagogies-73461331e735) and let me know what you think about the overall use of this tool to 'make' my argument.\n\nIn addition to the infographic/multimedia essay, I also decided that for my final piece I would try out Mozilla's Popcorn Maker and make my own video essay. Whether the end result was successful remains to be seen, I figured that I should continue my forays into learning new tools/methods with each post so please bare with my video essay. After reading the Picktochart post, check out this connected video [here](https://zoeleblanc.makes.org/popcorn/2mb9).\n\n**So what is a video essay?**\n\nAfter watching my video, you might still have this question and all I can say in my defense is that this video is my first and I won't be quitting my day job to be a video editor anytime soon. Nonetheless, I feel the video essay was actually ideal for my argument, as I was making an original argument that could benefit from some dramatic music and stirring visuals. Furthermore, my argument lacked any data visualizations or primary source materials.\n\nRoyal Roads University provides a good overview of video essays [here](http://libguides.royalroads.ca/mediaelements). The site defines video essays as using: \"audiovisual materials to present research or explore topics. Like written essays, they may contain an introduction, argument, supporting evidence, and conclusion.\"\n\nSimilar to textual ones, a key aspect to video essays is the narrative. A video essay allows for the visualization of a story and/or argument through a combination of imagery, audio, video, and sometimes text.\n\nSome great examples of video essays include Matthias Stork's [“Transmedia Synergies: Remediating Films and Video Games”](http://www.slate.com/blogs/browbeat/2013/01/15/movies_and_video_games_watch_a_great_video_essay_on_transmedia_video.html), which examines the relationship between movies and video games. Another great resource is Delve.tv, which is a site dedicated to creating video essays on complex ideas - you can check out [their essays](http://delve.tv/essays/). These examples demonstrate the potential for video essays when you can get high enough production value. A series of student productions can also be found at [http://videoessays.tumblr.com/](http://videoessays.tumblr.com/)\n\n**So why video essays? And how can video essays work in the classroom?**\n\nBy now you've hopefully read my ideas about using infographics and multimedia essays in the classroom, and I would generally place video essays into the same category. This type of assignment can build upon existing written essays as a either a companion assignment or a standalone piece. Similar to a traditional essay, video essays do follow a narrative. However, at least from my perspective, the format felt more unfamiliar than an infographic, and how you present evidence to support your argument was harder for me to visualize in video form. In some ways, video essays are closest to the historians' maxim of \"show, don't tell\" when it comes to crafting essays. Yet at the same time, due to the novelty of the video essay I wasn't really sure how to show or what to show when.\n\nNonetheless, I think that video essays are useful in the classroom but that I would caution that if like me you are a novice with audiovisual then be sure to bring in an expert and perhaps try out making your own video before you assign one. There are a number of conventions about videos that I completely ignored, and next time I would hope to do more preparatory work on how to pace and visualize my argument.\n\nThe last issue to consider with video essays, though this point is true for all online work, is the question of intellectual property and creative ownership. Unless you are shooting your own material for your video essay, you will likely be remixing videos and images that you find online. Contrary to academic standards of intellectual property, remixing is a completely acceptable and legal form of creative work. However, a key point for both educators and students is engaging with online standards of intellectual ownership - namely, the Creative Commons licenses. You can read more about the various types of Creative Commons licenses [here](https://creativecommons.org/licenses/), but generally speaking many of the videos on YouTube or Vimeo are available for use under some version of Creative Commons licenses. You can search on those sites for videos with certain licenses, and I would recommend using either Attribution, Attribution-ShareAlike, and/or Attribution-NonCommercial-ShareAlike. Using the Creative Commons licenses is also a great exercise for discussing the broader question of what constitutes intellectual property and academic standards of plagiarism.\n\n**So what tools should you use and how difficult is it to make video essays?**\n\nTo make my video essay, I used Mozilla's free tool [popcorn maker](https://popcorn.webmaker.org/), which allows you to use video clips from YouTube or Vimeo, images, audio, and text to create a web hosted video. Popcorn maker is fairly straightforward and easy to use, with drag and drop functionality. At times the site could be glitchy, but for a free tool it worked pretty consistently. The other benefit is that you can share and embed the videos fairly easily.\n\n**Overall Assessment of Mozilla Popcorn Maker**\n\n    Allows for Creative Content Creation: A\n    Ease of Use: B\n    Open Source: A-\n    Ease to Publish or Share: B (because you cannot download your movies)\n    Ease of Assessing Learning: A\n    Ability to Integrate into Curriculum: B- (depending on your previous experience with video editing, as well as your students)\n\n**Recommendation: Great tool with a low barrier to use and high potential for innovative learning.**\n\n**Alternative tools?**\n\nIn addition to Popcorn Maker, I also wanted to mention some additional tools for video essays. First is iMovie for Macs or iSkysoft for PCs, which are two desktop options that are supposed to be fairly easy to use and offer more customization and templates then Popcorn Maker. However, if you want a web application I would also recommend checking out [eduCanon](http://www.educanon.com/index). EduCanon is a free site for educators to use in the classroom that allows you to create videos with embedded content like quizzes and additional information. I haven't used any of these tools, but all of them seem promising alternatives that have their own pros and cons.\n\n**Final Thoughts**\n\nOverall, I would highly recommend video essays as an addition to any classroom, but would caution that these types of assignments can often feel less rigorous to students. So I would advise a conscious effort to keep the emphasis on the overall goal of the video, and make sure that goal supports the learning outcomes of the class. That being said, I would also caution that any attempt to assign a video essay as a one week assignment or busy work might not be the best idea. Videos essays like normal essays take time to formulate, and often rely on a set of narrative and structural principles that the students need time to understand and internalize.\n\nHave you used video essays in your classroom? What was your experience? Do you have any videos to share? If yes, please feel free to post links in the comments!\n\nCheers,\n\nZoe\n "},{"id":"2015-05-15-workflow-and-teaching","name":"2015-05-15-workflow-and-teaching","content":"> This post was one I produced for my VIDL Series \"In Pursuit of Digital Pedagogy\", which you can read [here.](https://my.vanderbilt.edu/vidl/2015/05/in-pursuit-of-digital-pedagogy-workflow-teaching/)\n\nNow that the semester is over and grades are submitted, the campus feels like a sleepy oasis. Most professors and grad students are off doing research, and trying not to think of the fall. Yet, I think summer is perhaps the best time to start thinking about course planning, and especially about how to integrate digital pedagogy into the next semester. This past semester, one standout issue I noticed was the question of workflow and digital tools. In my experience, there are few things as secretive or idiosyncratic as an academic's workflow.\n\nAsk an academic about an ongoing research project? You better be ready for at least an hour long discussion.\nAsk an academic about how they organize their workflow? At best you'll get some brief comments on how 'their' system works, but mostly you'll get blank stares.\n\n![xkcdworkflow]({{site.baseurl}}/assets/img/xkcdworkflow.jpg)\n\nI think part of this blindness to the nuts and bolts of knowledge production is because academics in the humanities are trained to focus on the bigger picture of their research. Yet, I think this silence about workflows is detrimental, especially for undergraduates. Why do we spend semesters talking about topic sentences and proper citations, but never discuss how to organize notes, pdfs, primary data and intelligently work on writing revisions? After grading numerous papers, I'm not advocating for the dismissal of proper writing etiquette, which I think is a necessity for many students. Instead, I think we should expand teaching to include helping students learn productive workflow habits. And of course, I think digital tools have a large role to play in creating an effective workflow.\n\nSo in this post, I want to outline some potential ways for integrating teaching workflow into your classroom. At the end, I also have a number of links for more on particular tools for digital workflows, as well as some descriptions of academic workflows.\n\n### So what is a workflow?\nWikipedia defines it as \"an orchestrated and repeatable pattern of business activity enabled by the systematic organization of resources into processes that transform materials, provide services, or process information.\"\n\nWhile this definition is correct, I think a workflow is more defined by its characteristics. I particularly like Chad Black's outline on what a good workflow should have:\n\n    * platform independence and future proofing\n    * flexible files\n    * robust searching\n    * version control, lots of access and backup\n\nHowever, you define workflow, I think teaching workflow is incredibly important for helping students develop some of the more abstract skill sets such as critical thinking and clear communication. Furthermore, many students and professors (myself included) struggle to be organized and systematic researchers - an area where a conscious workflow can help.\n\n### So how to teach workflows?\n\n**1. Don't approach teaching workflow as a one-off session.**\nMany professors schedule one of their first class meetings for learning effective researching methods. Usually hosted at the library, these sessions teach students how to use library databases and find scholarly materials. While these sessions can be helpful, workflow is an iterative process that often involves repeating steps, as well as continually refining how you work. I think a more successful approach would be to begin a course with a broad overview of how you conceptualize a workflow and, especially, a research project. Then, over the course of the semester as different assignments come up, teach students various parts of these workflows - from how to find materials to organizing research materials to building databases to revising writing. Such an approach I think models more closely how many academics work, as well as underscoring the importance of workflow to students. I would encourage the use of mind mapping and brainstorming tools. Three of my favorites are Stormboard, LucidChart, and MyThoughts, but you can even just share a basic Google Doc.\n\n**2. Allow for diversity of workflows**\nMost of the blog posts on workflow are written by academics who are self-proclaimed technophiles. While I agree with most of these posts, I think that allowing students to use low or no-tech methods for workflow is important. I enjoy sometimes drawing outlines for papers and I often jot down research ideas in my notebook. Yet, I also want to emphasize that consistent and comprehensive practices in your workflow is critical. You don't want to end up with a bunch of loose leaf paper or thousands of unorganized files. So regardless of what tools you use for your workflow, encourage your students to be mindful in how they develop a workflow. If you use a combination of tech and non-tech, be sure to integrate the two whether through transcribing notes, taking photos, or printing out materials.\n\n**3. Remember Occam's Razor**\nWith the continual releasing of new productivity tools, I find myself always wanting to try the newest tool or gadget. Yet, the best workflow is the simplest one that allows for productive and effective work. For some people, that workflow involves working on a linux machine and for others it means using index cards. Sometimes students might have suggestions, so you could potentially create a collaborative workflow that you develop over the course of the semester. The key thing to remember though is consciously thinking about your workflow, and not allowing happenstance to govern how you or your students work.\n\nIn my discipline of history, there is a general tendency to privilege low or no tech for workflows. However, while I think you can use a mixed approach to workflows, I do think that professors need to start thinking about how digital tools can exponentially improve workflows. In particular, two of my favorite tools are Devonthink for databases and organizing research, and Scrivener for writing and planning out projects.\n\nDo you teach workflows to your students? Feel free to share suggestions on how to teach workflow and any tools you like to use.\n\nCheers,\n\nZoe\n\n* * * * * \n\n### List of blog posts on workflows \n\n* A great forum on digital research workflow at [Digital Humanities.org](http://digitalhumanities.org/answers/topic/share-your-digital-research-workflow) which resulted in the mega post for resources by Miriam Posner. An [\"Embarrassment of Riches\"](http://miriamposner.com/blog/embarrassments-of-riches-managing-research-assets/) is a must post for anyone looking to develop a digital workflow, and looking for a list of available tools (though one thing to note is that this post is from 2011).\n* An example [mind map of a workflow by Shawn Graham](https://bubbl.us/mindmap?h=9cd6f/12f200/64X0rKA2wjvAU).\n* William J Turkel offers comprehensive guide for developing a digital workflow using either pay [for programs or a linux machine](http://williamjturkel.net/how-to/).  He also has a great post on using [Devonthink and Scrivener](http://williamjturkel.net/2011/04/04/write-and-cluster/), which has helped me improve my use of these programs.\n* Chad Black's post I mentioned above also has a [great list of digital tools.](https://parezcoydigo.wordpress.com/2011/03/14/update-on-the-ever-changing-workflow/). Black also has a post on using [Devonthink to construct databases.](https://parezcoydigo.wordpress.com/2008/11/13/devonthink-for-historical-research-part-ii/)\n* Dan Royles writes about [Digital Workflows for the archives](http://chronicle.com/blogs/profhacker/digital-workflows-for-the-archives/53505), and he lists a number of tools that will be useful for various disciplines.\n* Amy Cavender writes about [Keeping the Workflow Simple](http://chronicle.com/blogs/profhacker/keeping-the-workflow-simple/41281), and her use of Byword and Dropbox.\n* Lincoln Mullen has a great piece on [How to Make Prudent Choices About Your Tools for your workflow.](http://chronicle.com/blogs/profhacker/how-to-make-prudent-choices-about-your-tools/51261)\n* Jason Shafer has a helpful post on [Going Paperless from Day One: Digital Academic Workflow for Graduate Students](http://www.gradhacker.org/2011/08/12/going-paperless-from-day-one-digital-academic-workflow-for-grads/), but that really applies to all academics.\n"},{"id":"2015-09-03-starting-fresh","name":"2015-09-03-starting-fresh","content":"> Fall is my favorite time of year.\n\nSomeone once asked me why and in a freudian slip I admitted that it was because of the first day of school. It was a prett nerdy admission, even for me. But it's honestly true. \n\nI've always loved that excitement when you start off new classes and get to see everyone from their summer adventures. I'm lucky enough that my chosen career has allowed me to continue to experience the early September new school year magic (and might in part be why academia has such an allure). But for the last three years, I've been abroad during September (Rabat, Tel Aviv, and now London). Luckily, London has some nice fall weather so I'm at least feeling that warm fall coziness.  \n\nIn the spirit of a new academic year and a fresh state, I've decided to finally clean up my web presence and get my website off the ground. I've realized over the last few years that I'm actually slightly addicted to building websites (websitophilia?) but not really blogging. In fact, I'm not really all that comfortable posting anything on the web, whether it's twitter, instagram, or reddit.[^1] However, as much as I enjoy being an internet lurker, I also want to start producing something, even if it's not a very good something (we all have to start somewhere right?).\n\nIf you've visited previous iterations of my personal site, you'll find most of the same material. But under the hood this site is all new. For the last version of my site, I bought a turbo charged wordpress theme.[^2] But I quickly realized that I don't need most of the features like a store front or members only area. \n\nI really like the look of [Lincoln Mullen](http://lincolnmullen.com) and [Jason Heppler's](http://jasonheppler.org) sites, so I decided to make the move to Jekyll and Markdown (both of which seem increasingly to be the norm for digital humanists). \n\nAlready I'm loving the simplicity of building up the site from the basics of a theme I bought[^3], and if you're considering making the change, I would highly recommend it. Afterall, fall is for making fresh starts.\n\n-Z\n\nUPDATE: just found this post on the Chronicle on [\"How to Curate Your Digital Identity as an Academic\"](http://chronicle.com/article/How-to-Curate-Your-Digital/151001/), which was kind of the impetus for this redesign. I've also tried to clean up my digital presence and get rid of all the half formed websites I've created over the years.\n\n* * *\n\n[^1]: Thinking about writing a post about navigating the public/private divide as a twenty-something professional. I know there's lots of posts on this topic, but I still often feel unsure if something is too personal or it's ok to be authentic...\n[^2]: Highly recommend [Theme X by themeco](\"http://theme.co/x/\") if you're looking for a crazily functional wordpress theme.\n[^3]: While I've always wanted to design my website from scratch, I unfortunately don't really have the time, so I bought the [Writer theme](\"http://adventurethemes.com/demo/writer/jekyll/v1-d-20-2/\") from Adventure themes. I would also recommend the free [Hyde theme](\"http://hyde.getpoole.com/\") and the [Jackman theme](\"http://demo.krownthemes.com/jackman/\").\n"},{"id":"2015-09-14-big-data-and-the-cold-war","name":"2015-09-14-big-data-and-the-cold-war","content":"<a name=\"backtotop\"></a>\nBig Data and the Cold War are two things that seem like they should go together. Both are big unwieldy entities. And both seem to drive scholars a bit batty. But with the exception of a few digital history projects, I haven't really ever come across the two together.[^1]\n\nThis all changed the past month, when big data and Cold War history did sort of come together for me as I was able to attend two separate conferences on each topic.[^2] Even though the two conferences were quite different in format and subject, I wanted to write and think about them together - kind of a forced engagement - even if it's just in my head, and now on my website. I’ve written down some of the major questions/problems/shifts that were discussed at these conferences, but what follows is in no way a faithful representation of these conferences (sorry, you’ll have to try and attend them next year). Rather, think of this post as my conference doodles come to life - incoherent and shoddily sketched, but hopefully the beginning of something much more.\n\nI still wanted to write a bit about each conference so I've created little subheadings. Feel free to jump ahead if you just want my ideas on the intersections between big data and Cold War history. \n\n> #### Jump to [Making Big Data Human](#makingbigdatahuman) | [European Summer School on Cold War History](#esscwh) | [Big Data and Cold War history](#bigdatacoldwar) \n\n***************\n\n<a name=\"makingbigdatahuman\"></a>\nThe first conference was one I found on [twitter](https://twitter.com/dhiptweets/status/637969086270599169), called Making Big Data Human. [^3]\n\n![Making Big Data Human Poster]({{site.baseurl}}/assets/img/makingbigdatahuman.png)\n\nLuckily, someone canceled last minute so I was able to attend as a participant and head to Cambridge for the first time. The conference was hosted by a great group called [Doing History in Public](http://doinghistoryinpublic.org). The conference was a day long and covered a whole host of topics - from web archiving to database and keyword searches to human geography and visualization. Marta Musso storified the twitter exchange [here](https://storify.com/martamusso/making-big-data-human), which gives a good live feed of the conference, as well as some of my thoughts that I won't rehash here. \n\nSo here are the (my) big thoughts from the conference:\n\n**1. How do we deal with inconsistency and uncertainty in big data?**\n   \n In the opening keynote, Jane Winters talked about the problems inherent to the patchiness of data collection, especially with respect to web archives. How do we know what’s missing in massive data set or the degree of accuracy in the data collection? Compounding this difficulty is the reliance of big data on keyword searching, algorithms, and curated web archives, which can be problematic when you consider how these entities may fail to show the gaps in data and flatten complexities though the presentation of materials (i.e. think a list of google search hits versus searching in physical archives). I don’t think this problem is actually an obstacle, but rather an opportunity to reconsider how we think and talk about our data in the humanities, allowing for some space between object and interpretation.\n\n We also had a great discussion about the limitations of databases and queries. I think these discussions are signs of a growing scholarly critique of how data has been and continues to be collected and organized. Yet, we still have a long way to go for how we incorporate the reality of the patchiness of data into our scholarly research and interpretations. For example, we all know archives are abstractions but more often than not we hide many of the limitations of our studies in the footnotes. This approach is less productive in the context of big data, which requires fairly explicit discussion regarding the dataset’s specific parameters. Hopefully, the broader scope of evidence available through “big data” can help historians become a bit more honest about their data and analyses.\n\n**2. How do we identity and work with institutional structures and overcome institutional obstacles to big data in the humanities?**\n    \n A secondary and largely connected theme was that big data projects require] collaborations across disciplines, career stages, and institutions. The conference was great in actually bringing together scholars from across the sciences and the humanities. But it can be difficult to find collaborators in other departments. Furthermore, collaborating raises questions about the intellectual ownership of these digital projects, particularly for humanists who cannot program. In the UK and the EU more so than in the US, there's a tendency to fund large scale big data initiatives, which is great for the scope of the project, but poses challenges regarding the division of labor between a single Primary Investigator and many postdocs and students. How this will be resolved remains to be seen, but clearly some of the best collaborations are happening on campuses were some type of infrastructure exists to encourage and facilitate cross-disciplinary collaborations.\n\n**3. How do we define big data?**\n    \n Lastly, we often returned to the theme of definitions and nomenclature in big data. How do we define big data? Is it merely a large data set? Or is a set of tools? Or even more profoundly, a new methodological and intellectual approach for the humanities? At the end of the conference, we still hadn’t come to one definitive answer, and like most things in the humanities, I doubt we ever will (which I actually think is a good thing).\n\nMany of the speakers and participants in the conference almost immediately started slipping between big data and digital history, which for me raised questions of the overlap between the two. There was also a fairly strong critique over whether big data was anything new or simply the latest iteration of the computational approach first pioneered in the 60s and 70s. Personally, I believe that the changes in web technology and the ability to store and manipulate data has fundamentally altered the potential for big data and digital history, but placing this shift within the context of the early computing revolution is important for not overly exaggerating our current potential.\n\nConnected to this question of definition is also a clear need for some way to evaluate the quality of big data and digital history projects. With the AHA releasing its guidelines this summer, clearly the profession is moving in that direction. However, at the conference, many of the critiques revolved around the absence of applying the same scholarly critiques to big data that are applied in more traditional scholarship. Bridging this gap is going to be tough, but increasingly departments are encouraging students and faculty to experiment with digital projects, which will hopefully lead to a more widespread engagement with big data across the humanities.\n\n***************\n<a name=\"esscwh\"></a>\nWith these questions in mind, I jetted off to Rome for the [European Summer School on Cold War History](http://www.lse.ac.uk/IDEAS/Projects/Cold%20War%20Studies/Events/Cold%20War%20Summer%20School/CWSS2015CfP.aspx) . Organized by a consortium of European Universities, this year's hosts were Università Roma Tre e Università Roma Tor Vergata. At the conference, I presented a paper on the impact of the Congo Crisis on Cairo, which I'll hopefully blog about at a later date. I unfortunately didn't tweet at all during the conference (I'm not sure anyone did actually), so I don't have an overview of all the papers or discussions.\n\nThe conference itself was at the Societa Geografia Italiana, which is in a  gorgeous old italian villa in Rome.\n\n![View from the conference]({{site.baseurl}}/assets/img/romeview1.jpg)\n\n![View from the conference]({{site.baseurl}}/assets/img/romeview2.jpg)\nView from the Conference \n\nGiven that the Cold War spanned a huge swath of time, the papers at the conference covered a wide variety of topics. I won't cover each one here, but just touch on some broader questions/topics.\n\n**1. How do we define the Cold War?**\n\n Quite a bit of ink has been spilt on this question, but I was struck by how little we actually discussed the Cold War as an entity, given that this conference addressed the topic (which I actually think is a positive development, instead of getting stuck in circular arguments). I think what the Cold War means really depends on your particular research question. For my work, the Cold War is both a temporal marker and also a force that limits the space for third world solidarities. For others, the Cold War is a historical object that was constructed or a historical actor that shaped cultural identities. I think this multiplicity is a sign of the richness of the scholarship, but the conference did make me think more deeply about what the Cold War means for my work, and how a Cold War lens can illuminate different dynamics.\n\n**2. Rise of spatial and intellectual history lenses**\n\n I was also quite pleased to see a number of scholars using spatial and intellectual history lenses, though often implicitly. I think that with the plethora of sources available to modern historians, we sometimes are a little more lazy with respect to the theoretical and analytical framing of our research. Yet, at the conference many of the papers engaged with these analytics, with a focus on spaces like ports and islands, as well as an emphasis on tracing intellectual histories of expertise and discourses. I'm always struck by the “emergent-ness” of scholarship around a particular lens. Did everyone just hear about these topics in their graduate seminars, or are we all truly the product of our times? Suppose the answer is probably a bit of both. I hope that this trend continues in part selfishly, because it’s the type of work I find most interesting, but also because I think it will truly open up new fruitful subfields of scholarship. \n\n**3. Pushback on transnational as a framework**\n\n Although the term “transnational” was thrown around rather liberally at the conference, on the whole, most of the papers actually focused on local histories within internationalized dynamics, rather than transnational movements. While some stories are inherently transnational (international organizations for example), I think qualifying and limiting the use of transnational is important. Personally, I often feel that transnational histories tend to skew towards a neoliberal imaging of movement, which often ignores power dynamics and states, as well as ignoring the instrumentality of international solidarities/events for local spaces. In simpler terms, very few topics are truly transnational whereas I think most historians are actually working on local spaces that become internationalized, even if they're studying social movements or the movements of goods. So I was quite pleased that even though I was at a conference on something profoundly global like the Cold War, the term transnational was not thrown around as liberally or loosely as I’ve seen in the past.\n\n******\n<a name=\"bigdatacoldwar\"></a>\n\nSo now coming back to this question of how these two incredibly broad topics relate to one another. \n\nThe most obvious overlap is the corpus of materials from the Cold War, and how big data projects might help us understand these archives. This idea is increasingly becoming a reality with the use of digital cameras. However, unlike 19th century historians, Cold War historians still have to contend with copyright laws. In my research, this reality produces counterintuitive emphasis on declassified government documents over press materials, which are still under copyright law. \n\nBig data methods also open the opportunity for truly global histories of the Cold War, using a scale of materials beyond the capacity of one researcher to synthesize. Many of the papers at the ESSCWH used multinational and multilingual sources. However, many of the applications for OCR and text mining privilege romantic languages, which at least for now limits and could potentially skew these types of projects. I’m still struggling with OCR on Arabic script, which makes it difficult to see large-scale patterns in the Arabic daily newspapers I work with.\n\nExcepting these limits, big data provides incredible opportunities to visualize narratives in new ways, as well as to trace patterns over time and space. Ultimately, I think big data will help historians of the Cold War be more honest about the gaps in our data and our archives - an important and necessary shift for historians. \n\nI also think that thinking about the Cold War can make us more critical about big data. First and foremost, much of higher education was shaped during the Cold War, especially disciplinary and departmental divisions. Historicizing these divisions is critical for opening up spaces for collaborations. At the moment most historians using big data are either using previously digitized or digitally born materials as the basis for their corpus. However, as OCR and cloud services improve, the potential for big data from text sources will increasingly become a reality. Most humanities scholars, and especially historians, are not equipped with the skills to work with these resources and so finding collaborators in the social and computer sciences is going to become critical. \n\nThinking about these questions together has, for me at least, started the wheels turning about  the obstacles of copyright, collaboration, and data collection that I think has prohibited Cold War historians from adopting more of the the digital history/big data methods employed by historians of other time periods. I hope that in the future, digital historians will more clearly illustrate the overlap between these two topics. Until then, I guess I'll have to keep thinking about them, and hope you do too.\n\n-Z\n\n******\n **Jump [back to top](#backtotop)**\n\n[^1]: When I say a few, I'm really thinking of two in particular: Micki Kaufman's [Quantifying Kissinger](http://blog.quantifyingkissinger.com) and Matthew Connelly's [History Lab](http://blog.quantifyingkissinger.com). If you know of any please let me know!\n[^2]: Sadly yes this is a post about conferences and not how big data can solve the Cold War. Although I'm sure someone out there is working on that...\n[^3]: Yes, twitter can be useful sometimes. I found this tweet after looking at the IHR digital history seminar page, I checked out their twitter stream [#dhist](https://twitter.com/search?q=%23dhist&src=typd) and [@IHRDigHist](https://twitter.com/IHRDigHist)\n"},{"id":"2016-02-12-digital-history-workshop","name":"2016-02-12-digital-history-workshop","content":"At Vanderbilt, our main departmental gathering is the Vanderbilt History Seminar (aka VHS). In recent years, VHS has started funding small mini workshops on a variety of topics. Last year, I presented at one on the concept of rituals of belonging in our research. This fall I proposed and had accepted a set of two workshops on digital history. You can read my proposal [here], but essentially my desire was to start a conversation in the department about how to meaningfully produce and evaluate digital history scholarship. In many ways, the impetus was the AHA’s recent Guidelines for Evaluating Digital History, but the proposal was also self-interested. \n\nSince last May, I’ve been engaging more deeply with the literature on digital history/humanities, after a great Skype call with Micki Kaufman, who encouraged me to make the leap. So far I’ve presented some preliminary research at SHAFR in June, and eventually designed and developed this website in September. But I’ve been a bit hesitant on how to move forward more meaningfully with digital history in my scholarship. \n\nIn part, I’ve been busy with archival work and dissertation writing. However, as I’ve become more conversant and interested in digital history, I’ve also become increasingly conflicted, and even at times skeptical, over the term/field. I don’t want to rehash any of the debates over nomenclature here, but at least personally, I’m still unsure if I see digital history as something similar to oral history (as a new methodology) or something more akin to cultural or social history (as in a new analytic for asking historical questions). I know it doesn’t have to be one or the other, but the question boils down to whether one is a digital historian or whether every historian should be using some form of digital [insert tool/method]. While I realize we won’t solve this dilemma in the workshop, I’m hoping that the workshop produces some new understandings about what constitutes digital history.\n\nThis week I’ve been going back over blog posts, articles, and digital projects to create a list of materials for the workshop.  Somehow I missed it when he initially posted it, but I found Cameron Blevins’ blog post [“The Perpetual Sunrise of Methodology”](http://www.cameronblevins.org/posts/perpetual-sunrise-methodology/). and wow he really hits the nail on the head. I encourage everyone to read it, but I also wanted to post this particular section that really resonated with me.\n\n>“But there is one area in which digital history has lagged behind: academic scholarship. To be clear: I’m intentionally using “academic scholarship” in its traditional, hidebound sense of marshaling evidence to make original, explicit arguments. This is an artificial distinction in obvious ways. One of digital history’s major contributions has, in fact, been to expand the disciplinary definition of scholarship to include things like databases, tools, and archival projects. The scholarship tent has gotten bigger, and that’s a good thing. Nevertheless there is still an important place inside that tent for using digital methods specifically to advance scholarly claims and arguments about the past.\n\n>In terms of argument-driven scholarship, digital history has over-promised and under-delivered. It’s not that historians aren’t using digital tools to make new arguments about the past. It’s that there is a fundamental imbalance between the proliferation of digital history workshops, courses, grants, institutes, centers, and labs over the past decade, and the impact this has had in terms of generating scholarly claims and interpretations. The digital wave has crashed headlong into many corners of the discipline. Argument-driven scholarship has largely not been one of them.”\n\nThe rest of the post is great too, but when this passage really made me want to high five my screen and shout YES! All my protean frustrations I realize that digital history doesn’t just have to be about scholarship, but I’m excited to see that others are both identifying this gap, and producing examples of great digital historical scholarship.\n\nOur first workshop is this morning, and beneath the excitement and nerves, I’m hoping our workshop can start a discussion of how historians can engage more directly with digital history projects. I hope we also help people start thinking about how their research questions might develop through a digital history lens. These goals are a tall order for a workshop, but already I’ve been pleasantly surprised at the amount of interest. If you’re at Vandy and interested in attending, feel free to stop by (we still have a few more seats) and you can check out details on our website [vhsdist.wordpress.com](https://vhsdhist.wordpress.com/). I’ll try and write about the experience of the first workshop over the weekend. \n\nAlso this morning, just found that the latest American Historical Review has a whole roundtable about [Digital History](http://ahr.oxfordjournals.org.proxy.library.vanderbilt.edu/content/121/1.toc). Talk about timing!\n"},{"id":"2017-06-23-depictions-of-decolonization-shafr-2017","name":"2017-06-23-depictions-of-decolonization-shafr-2017","content":"For SHAFR 2016, I co-organized with Micki Kaufman the first digital history panel at the conference. Our panel was a lot of fun, and we published abbreviated versions of our talks in SHAFR's newsletter Passport.\n\nThis past year (2017), I wasn't sure I was going to travel to SHAFR but I was asked to join another digital history panel, and agreed to present some preliminary research avenues. The panel was titled, \"Doing Digital History\", and Micki and I both presented again with Marc Selverstone providing excellent commentary. \n\nI don't usually post my conference talks, but I wanted to share this one for other scholars who might be interested in using digital image analysis in their studies of public diplomacy. \n\n****\n\n\n![slide1]({{ site.baseurl }}/assets/img/Slide01.jpg)\n\nDepictions of Decolonization: Cairo, Anti-Colonialism, and Digital Image Analysis\n\nGood afternoon everyone. Before I get started I want to thank Marc for agreeing to chair this panel and to Micki for helping bring this panel together. Last year we had a great discussion at our \"Doing Digital Diplomatic History\" panel at SHAFR and I’m excited to continue that conversation today.\n\n![slide2]({{ site.baseurl }}/assets/img/Slide02.jpg)\n\nLast June, I presented on using digital history to analyze diplomatic dispatches from the American embassy in Cairo in the 1950s and 60s. I’m still working on that part of my research, but today I’m shifting gears away from textual sources towards print images. One of the most frustrating aspects of current text analysis methods is that as part of the data cleaning process you often remove the images from the document. While this approach is fine for a study of hundreds of novels, for historical magazines and newspapers this method throws out some of the most interesting historical evidence. So today, I want to share how I’ve worked to integrate images into my digital history methods and research, and hopefully provide some insight into these new research directions for historians interested in studying images in foreign relations.\n\n![slide3]({{ site.baseurl }}/assets/img/Slide03.jpg)\n\nSo for some background, my dissertation explores Cairo in the 1950s and 60s as a hub for international anti-colonial media production. I trace how Cairo, more so than any other Third World capital, sought to leverage various medias to construct international anti-colonial solidarities. One of the more famous efforts was Radio Cairo, which was broadcast across the continent in multiple languages. And in this slide you can see their broadcast schedule from the summer of 1964.\n\nThe other arena where Cairo was pre-eminent was as a publication hub with the government funding numerous newspapers and magazines, as well as offering anti-colonial activists from other countries resources to print materials, all of which circulated across the anti-colonial world. In my research, I explore these sources, as well as newspapers from other Third World capitals to understand how the meanings of anti-colonialism shifted over this period. The other image in this slide is from one of these magazines, The Arab Observer, which is the publication I’m focusing on today, and I think this image is great representation of my dissertation.\n\n![slide4]({{ site.baseurl }}/assets/img/Slide04.jpg)\n\nSo obviously many diplomatic historians have already studied imagery and foreign relations whether through the lens of culture and diplomatic history, or more recently in studies of public diplomacy and propaganda. While there are large literatures on this subject, I want to mention two recently published books: Sonke Kunkel’s *Empire of Pictures *and Jason Parker’s *Heart, Minds, Voices*. Empire of Pictures explores the \"global flood of images\" that emerged in the 1960s, focusing particularly on the use of images in constructing American empire and power abroad. And a lot of my thinking on this subject draws heavily from Kunkel’s methodology, and especially his emphasis on pictures as historical actors. Parker’s *Heart, Minds, Voices *also provides an excellent overview of USIA attempts to counter Third World public diplomacy and to shift international public opinion. Both of these works underscore the importance of media as a political battleground, but the lens of public diplomacy really hasn’t fully been utilized in studies of non-Western foreign relations. So I’m trying bridge these studies of public diplomacies with literatures on non-Western media cultures. \n\nThe United Arab Republic under Gamal Abdel Nasser is a particularly interesting case study since most of the media was either state owned or censored. Thus, many of these publications offer a window into the Egyptian state’s prescriptive vision of anti-colonialism, especially in the absence of open government archives.\n\n![slide5]({{ site.baseurl }}/assets/img/Slide05.jpg)\n\nI first became interested in the symbolism of anti-colonialism in my research on the response to the Congo Crisis in Cairo. While most of my research involved diplomatic cables and speeches at the United Nations, I was surprised to keep finding pictures of Patrice Lumumba’s widow and children in various Egyptian newspapers and magazines in the early 1960s. I started wondering how these types of pictures were used to symbolize the UAR’s vision for anti-colonial solidarities.\n\n![slide6]({{ site.baseurl }}/assets/img/Slide06.jpg)\n\nA more famous image of these anti-colonial solidarities is this image of Nasser, Nehru, and Tito from the Brioni meeting in July 1956, which many mark as the beginning of the non-aligned movement. These types of pictures often become book covers, but what about their role in shaping this history?\n\n![slide7]({{ site.baseurl }}/assets/img/Slide07.jpg)\n\nFor a quick tongue and cheek answer, one just has to check Twitter to see what has now become a genre of images of Trump being compared to Obama in what are generally termed ‘photo-ops’. As a Canadian, I chose these two, and in many ways these images speak for themselves. Yet, I also want to share these images as a way to consider the ways in which pictures can define political narratives and moments. \n\nBut today I also want us to consider this same question but with a thousand or tens of thousands of these images. This proposition might feel overwhelming or exciting depending on your perspective, but regardless this hypothetical is increasingly becoming a reality. So how should diplomatic historians proceed?\n\nThe answer to that question is one that no historian along can provide, but today I’ll try and discuss some of these exciting new research avenues, along with some of the frustrations and ethical grey areas of deploying computer vision. \n\n<iframe src=\"https://giphy.com/embed/zaezT79s3Ng7C\" width=\"480\" height=\"271\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/liz-lemon-lets-do-this-zaezT79s3Ng7C\">via GIPHY</a></p>\n\n![slide9]({{ site.baseurl }}/assets/img/Slide09.jpg)\n\nThe first step in any digital history project is getting your data. This activity is activity is critical to any digital history project, and most of the existing research on computer vision relies on either born digital images from social media or from previously digitized corpuses, like the Chronicling America project from the Library of Congress. For most historians, these two categories cover a lot of temporal ground. However, for modern historians we’re stuck between copyright law that’s slowly inching up the 1920s and digital archives that really only emerged in the late 1990s. This reality means that there’s limited existing publicly available datasets for the mid-twentieth century. One of the biggest struggles in my research has been finding efficient ways to create my own image collections. However, relying on previously created datasets isn’t without its own pitfalls. For historians, collecting archival sources is as much a part of our research as writing, and this reality remains true even if you’re working with digital images.\n\nSome existing image management tools include flickr, photo libraries, DevonThink, and various cloud storage offerings. Most of these offerings provide limited means to transform images. This past May, the Roy Rosenzweig Center for History and New Media at George Mason University released Tropy (NOTE:  https://tropy.org/), which is probably the best photo management tool I’ve come across. If Tropy had been available earlier, I might have used it more in my research. But instead like the ambitious grad student I am, I actually built my own application that I’m calling Image Lucida to be my dream research collection platform. That being said, a lot of what I do with Image Lucida can be achieved with freely available sources. \n\nMy process involves uploading my archival images, organizing them into the relevant folders and adding meta-data, like publication issue, page number, and tags. One of the most difficult steps in this process beyond building the application is creating a standardized ontology for organizing and tagging these images. This cleaning and curation of these sources is the most time consuming, but I believe is a critical step in the research process. Afterall, a different historian interested in different questions might tag certain images differently or organizing images in different hierarchies. \n\n![slide10]({{ site.baseurl }}/assets/img/Plots_of_covers.gif)\n\nAlso before I go into how I’ve used digital image analysis in my research, I first want to explain a bit about how computers understand images. Images, regardless of file type, are actually a set of pixels which can be read by a machine as a series of numbers, usually in a matrix. Most digital image analysis can be divided into three categories: the use of human tagging of images to identify features, analyzing meta-data that was either entered by humans or generated from image files, and lastly computer vision libraries and proprietary databases that are used to analyze pixels and extract image features. Now there’s a lot of overlap between these categories, but a helpful distinction between these methods is whether a method uses human interpretation as a basis for analysis or computed statistics of pixel groupings.\n\n![slide11]({{ site.baseurl }}/assets/img/Slide11.jpg)\n\nAfter adding the metadata, I utilize a combination of OCR and computer vision resources. The two main ways I use computer vision is to clean my data and analyze it.\n\nSo for images that I’ve uploaded, I first extract any text using either the Tesseract or Google Vision APIs. Then If the source does have images, I run it through a computer vision algorithm, called Otsu thresholding, that automatically removes the images. This slide is an example of what the algorithm produces from a cover of The Egyptian Gazette. So as you can see it’s fairly accurate though newspapers are particularly difficult for computer vision algorithms because they are so busy. \n\n![slide12]({{ site.baseurl }}/assets/img/Slide12.jpg)\n\nFor today, I’ve processed a number of the issues from The Arab Observer: The Non-Aligned Weekly, which was a state-funded periodical published in Cairo from 1960-1966. Over the course of this period, The Arab Observer circulated throughout anti-colonial, leftist, and revolutionary networks. Full disclosure, what I’m presenting today is fairly preliminary analysis, but I’ll also talk a bit about where I hope to take this research. \n\nThe first cover here is the first issue of The Arab Observer that I’ve found from June 26 1960 and the second cover is the last issue of the Arab Observer that I have from October 31, 1966. I have almost 300 issues of the magazine in my collection, though I have found catalogues listing the publication up until 1975. \n\nUsing a combination of tagging, pixel analysis, and the Google Vision API, I have annotated these covers to try and get a sense of how their symbolism changes over this time period.\n\n![slide13]({{ site.baseurl }}/assets/img/Slide13.jpg)\n\nThe first question I wanted to explore is which places appeared more often in the covers. Overwhelmingly Cairo is the location for the covers, though towards the end of this period the covers became increasingly abstract and thus they did not have a geographic location. Also for some reason this map represents null values as California, which I left as an interesting question.\n\n![slide14]({{ site.baseurl }}/assets/img/Slide14.jpg)\n\nAs you would assume, Gamal Abdel Nasser appears frequently on the cover (approx. 28 times). Though the range of subjects varies a great deal. One of my favorite series is looking at the covers from around July 23, which is the anniversary of the Free Officer’s Revolution.\n\n![slide15]({{ site.baseurl }}/assets/img/Slide15.jpg)\n\nWhile I have tried to extract places and people from these images, I have also been interested in how the themes and formats of the covers change over time. As you can see in this slide, Anti-colonialism was initially the overwhelming focus of the magazine, but over this period you can see a shift in coverage towards development and what I’ve termed cultural heritage.\n\n![slide16]({{ site.baseurl }}/assets/img/Slide16.jpg)\n\nThis shift is also reflected in the format of the covers. For anti-colonial covers, initially the covers utilized photographs of leaders, but starting in 1962 the magazine started to depict leaders with hand drawn portraits. This continued until about 1965 when the magazine started depicting more abstract covers, with the name becoming The Arab Observer and the Scribe. I argue that this shift towards a more literary and cultural heritage focus for the magazine, coincided with a shift in the tenor of anti-colonial politics in Cairo. \n\n![slide17]({{ site.baseurl }}/assets/img/Slide17.jpg)\n\nWhile the magazine still featured some coverage of anti-colonial leaders and conferences in Cairo, it no longer depicted political events through radical cartoons or strident headlines. While this change may be in part due to changing editorial boards, I also argue that it represents shifting meanings of anti-colonialism in Cairo - away from more radical rhetoric and international focus towards a more nationalist approach, focusing on development and cultural heritage as part of this anti-colonial platform.\n\n![slide18]({{ site.baseurl }}/assets/img/Slide18.jpg)\n\nPart of my interest in anti-colonialism is exploring how the emotive meanings shift over this period. To that end, I also utilized Google Vision’s face detection algorithm to try and see if it could detect the ‘emotions’ in the faces in these covers. This approach is not particularly nuanced since the algorithm only detects for joy, sorrow, surprise, and anger and the face detection is far from perfect. \n\n![slide19]({{ site.baseurl }}/assets/img/Slide19.jpg)\n\nNonetheless, this graph offer another feature for analyzing the symbolism of these images. \n\n![slide20]({{ site.baseurl }}/assets/img/Slide20.jpg)\n\nFinally returning that initial image of Nasser, Nehru, and Tito, I have also computed the similarity similarity between this image and all the other covers.\n\n![slide21]({{ site.baseurl }}/assets/img/Slide21.jpg)\n\nIn the future, I hope to use this method to trace how images travel between publications in Cairo, as well as beyond in other Third World coverage of events, which I believe can help us understand the media theory that animated a lot of Third World activism.\n\nSo what are my next steps? While these computer vision algorithms are great for initial exploratory analysis, where I’m most interested in pushing further is using the tags and annotations I’ve done of these images as the basis for a supervised machine learning classifier, which can extend my interpretation over a much larger scale of images. I also hope to start bridging my earlier text analysis with these images, calculating how the symbolism in these images supports and diverges from the surrounding text in these magazines and newspapers.\n\nEven though my analysis has some ways to go, there are existing projects that utilize a wide range of methods and utilize a number of other available tools. While computer vision is predominantly a field in computer science department, increasingly digital humanists are exploring the application of digital image analysis to humanities research. \n\n![slide22]({{ site.baseurl }}/assets/img/Slide22.jpg)\n\nA pioneer has been Lev Manovich and his work with the Cultural Analytics Lab. Some of his more famous work includes the 2009 project \"Timeline,\" that visualized 4,535 covers of Time magazine (1923-2009), and the project “Selfie City” that explores Instagram selfie trends for different cities. (NOTE:  http://selfiecity.net/) \n\n![slide23]({{ site.baseurl }}/assets/img/Slide23.jpg)\n\nAnother large scale project is the Yale Digital Humanities Center’s Robots Reading Vogue created by Peter Leonard and Lindsay King, which allows students and researchers to use 6TB of data to explore Vogue’s 100 year publication history. (NOTE:  http://dh.library.yale.edu/projects/vogue/about.shtml) \n\n![slide24]({{ site.baseurl }}/assets/img/Slide24.jpg)\n\nOther great examples include Matthew Lincoln’s study into genre diversity of seventeenth-century Dutch painting and printmaking (NOTE:  http://matthewlincoln.net/2016/07/13/dh2016-measuring-genre-diversity-in-seventeenth-century-dutch-painting-and-printmaking.html), Thomas Padilla’s Three Dimensional analysis of  the sci-fi magazine IF  (NOTE:  http://www.thomaspadilla.org/2016/03/02/3dscifi/), and John Resig and Ryan Baumann who have used different tools to analyze image similarity in art museum collections. (NOTE:  https://ryanfb.github.io/etc/2015/11/03/finding_near-matches_in_the_rijksmuseum_with_pastec.html & http://journalofdigitalhumanities.org/3-2/using-computer-vision-to-increase-the-research-potential-of-photo-archives-by-john-resig/)\n\nAs these titles illustrate, much of this research is occurring at the intersection of digital art history and cultural analytics, which makes sense since these researchers are interested in the visual analysis of large datasets. While these projects largely leverage existing datasets, they do provide a great resource for starting to consider the different types of research avenues that digital image analysis can provide. \n\nI would highly recommend looking at these projects if you’re considering trying to use digital image analysis. Digital humanists and social scientists have also been some of the strongest critics of these computer vision and artificial intelligence algorithms and their applications to everything from state surveillance to image searches. Using resources like the Google Vision API in my application raises questions about how ownership of this data, as well as its uses for other algorithms like state surveillance.\n\nUltimately, computer vision is still a relatively new field, and many of the tools available are not as refined as those for text analysis. Nonetheless, the ability to collect and curate thousands of images is increasingly becoming a reality for historians. For my research, integrating digital image analysis has helped further my exploration into the symbolism of anti-colonialism and opens up the opportunity to explore many new questions. For diplomatic historians interested in public diplomacy, images have already proven to be fertile ground, and I believe integrating digital image analysis into those analyses will enable historians to our hypotheses on a much larger scale. However, I also realize that the barrier to entry is not as easy as some textual analysis tools and understanding the output of computer vision algorithms can be difficult. I hope today I have demonstrated some value for these methods and shown the potential of this newer research method.\n\n![slide25]({{ site.baseurl }}/assets/img/Slide25.jpg)\n\nIf you’re interested, under the hood of this application I’m using a combination of three different computer vision and image analysis libraries that are available in python: Scikit-Image, Pillow, and OpenCV. All of my code is available on Github, and I would be happy to discuss more later.\n\n \n\n"}]